{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from svm.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "test dataMat shape: (980, 400), test dataLabel len: 980 \n",
      "Recognition  0 spent 12.4688s.\n",
      "errorCount: 11.\n",
      "computing score spent 18.593750s.\n",
      "score: 0.988776.\n",
      "error rate is 0.011224.\n",
      "test dataMat shape: (1135, 400), test dataLabel len: 1135 \n",
      "Recognition  1 spent 19.9844s.\n",
      "errorCount: 19.\n",
      "computing score spent 10.359375s.\n",
      "score: 0.983260.\n",
      "error rate is 0.016740.\n",
      "test dataMat shape: (1032, 400), test dataLabel len: 1032 \n",
      "Recognition  2 spent 9.4219s.\n",
      "errorCount: 97.\n",
      "computing score spent 9.484375s.\n",
      "score: 0.906008.\n",
      "error rate is 0.093992.\n",
      "test dataMat shape: (1010, 400), test dataLabel len: 1010 \n",
      "Recognition  3 spent 9.2344s.\n",
      "errorCount: 78.\n",
      "computing score spent 9.718750s.\n",
      "score: 0.922772.\n",
      "error rate is 0.077228.\n",
      "test dataMat shape: (982, 400), test dataLabel len: 982 \n",
      "Recognition  4 spent 12.8438s.\n",
      "errorCount: 60.\n",
      "computing score spent 18.562500s.\n",
      "score: 0.938900.\n",
      "error rate is 0.061100.\n",
      "test dataMat shape: (892, 400), test dataLabel len: 892 \n",
      "Recognition  5 spent 13.5938s.\n",
      "errorCount: 121.\n",
      "computing score spent 8.109375s.\n",
      "score: 0.864350.\n",
      "error rate is 0.135650.\n",
      "test dataMat shape: (958, 400), test dataLabel len: 958 \n",
      "Recognition  6 spent 8.6875s.\n",
      "errorCount: 40.\n",
      "computing score spent 8.703125s.\n",
      "score: 0.958246.\n",
      "error rate is 0.041754.\n",
      "test dataMat shape: (1028, 400), test dataLabel len: 1028 \n",
      "Recognition  7 spent 9.3750s.\n",
      "errorCount: 84.\n",
      "computing score spent 9.437500s.\n",
      "score: 0.918288.\n",
      "error rate is 0.081712.\n",
      "test dataMat shape: (974, 400), test dataLabel len: 974 \n",
      "Recognition  8 spent 9.6562s.\n",
      "errorCount: 115.\n",
      "computing score spent 17.062500s.\n",
      "score: 0.881930.\n",
      "error rate is 0.118070.\n",
      "test dataMat shape: (1009, 400), test dataLabel len: 1009 \n",
      "Recognition  9 spent 19.1094s.\n",
      "errorCount: 109.\n",
      "computing score spent 9.578125s.\n",
      "score: 0.891972.\n",
      "error rate is 0.108028.\n",
      "Testing All class total spent 245.931651s.\n",
      "All error Count is: 734.\n",
      "Average accuracy is: 0.925450.\n",
      "Average error rate is: 0.074550.\n",
      "number  TrueCount  ErrCount\n",
      "0       969        11\n",
      "1       1116        19\n",
      "2       935        97\n",
      "3       932        78\n",
      "4       922        60\n",
      "5       771        121\n",
      "6       918        40\n",
      "7       944        84\n",
      "8       859        115\n",
      "9       900        109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importer\n",
    "import sys\n",
    "import time\n",
    "import svm\n",
    "import os\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "def svmtest(model_path):\n",
    "    path = \"D:\\jupyterPJ\\svm\"\n",
    "    tbasePath = os.path.join(path, \"data\\\\Mnist-image\\\\test\\\\\")\n",
    "    tcName = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    tst = time.clock()\n",
    "    allErrCount = 0\n",
    "    allErrorRate = 0.0\n",
    "    allScore = 0.0\n",
    "    ErrCount=np.zeros(10,int)\n",
    "    TrueCount=np.zeros(10,int)\n",
    "    #加载模型\n",
    "    clf = joblib.load(model_path)\n",
    "    print(1)\n",
    "    for tcn in tcName:\n",
    "        testPath = tbasePath + tcn\n",
    "        # print(\"class \" + tcn + \" path is: {}.\".format(testPath))\n",
    "        tflist = svm.get_file_list(testPath)\n",
    "        # tflist\n",
    "        tdataMat, tdataLabel = svm.read_and_convert(tflist)\n",
    "        print(\"test dataMat shape: {0}, test dataLabel len: {1} \".format(tdataMat.shape, len(tdataLabel)))\n",
    "        # print(\"test dataLabel: {}\".format(len(tdataLabel)))\n",
    "        pre_st = time.process_time()\n",
    "        preResult = clf.predict(tdataMat)\n",
    "        pre_et = time.process_time()\n",
    "        print(\"Recognition  \" + tcn + \" spent {:.4f}s.\".format((pre_et - pre_st)))\n",
    "        # print(\"predict result: {}\".format(len(preResult)))\n",
    "        errCount = len([x for x in preResult if x != tcn])\n",
    "        ErrCount[int(tcn)]=errCount\n",
    "        TrueCount[int(tcn)]= len(tdataLabel)-errCount\n",
    "        print(\"errorCount: {}.\".format(errCount))\n",
    "        allErrCount += errCount\n",
    "        score_st = time.process_time()\n",
    "        score = clf.score(tdataMat, tdataLabel)\n",
    "        score_et = time.process_time()\n",
    "        print(\"computing score spent {:.6f}s.\".format(score_et - score_st))\n",
    "        allScore += score\n",
    "        print(\"score: {:.6f}.\".format(score))\n",
    "        print(\"error rate is {:.6f}.\".format((1 - score)))\n",
    " \n",
    "    tet = time.process_time()\n",
    "    print(\"Testing All class total spent {:.6f}s.\".format(tet - tst))\n",
    "    print(\"All error Count is: {}.\".format(allErrCount))\n",
    "    avgAccuracy = allScore / 10.0\n",
    "    print(\"Average accuracy is: {:.6f}.\".format(avgAccuracy))\n",
    "    print(\"Average error rate is: {:.6f}.\".format(1 - avgAccuracy))\n",
    "    print(\"number\",\" TrueCount\",\" ErrCount\")\n",
    "    for tcn in tcName:\n",
    "        tcn=int(tcn)\n",
    "        print(tcn,\"     \",TrueCount[tcn],\"      \",ErrCount[tcn])\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x=list(range(10))\n",
    "    plt.plot(x,TrueCount, color='blue', label=\"TrueCount\")  # 将正确的数量设置为蓝色\n",
    "    plt.plot(x,ErrCount, color='red', label=\"ErrCount\")  # 将错误的数量为红色\n",
    "    plt.legend(loc='best')  # 显示图例的位置，这里为右下方\n",
    "    plt.title('Projects')\n",
    "    plt.xlabel('number')  # x轴标签\n",
    "    plt.ylabel('count')  # y轴标签\n",
    "    plt.xticks(np.arange(10), ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "    plt.show()\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    path = \"D:\\jupyterPJ\\svm\"\n",
    "    model_path=os.path.join(path,'model\\\\svm.model')\n",
    "    svmtest(model_path)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
